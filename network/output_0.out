p2299
Requirement already satisfied: pip in ./venv/lib/python3.6/site-packages (21.2.4)
Requirement already satisfied: tensorflow-gpu==1.15 in ./venv/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.15.0)
Requirement already satisfied: tensorflow-probability==0.7.0 in ./venv/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (0.7.0)
Requirement already satisfied: matplotlib==3.1.0 in ./venv/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (3.1.0)
Requirement already satisfied: colorcet==2.0.1 in ./venv/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (2.0.1)
Requirement already satisfied: brokenaxes==0.3.1 in ./venv/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (0.3.1)
Requirement already satisfied: sacred==0.7.5 in ./venv/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (0.7.5)
Requirement already satisfied: pymongo==3.8.0 in ./venv/lib/python3.6/site-packages (from -r requirements.txt (line 7)) (3.8.0)
Requirement already satisfied: keras-preprocessing>=1.0.5 in ./venv/lib/python3.6/site-packages (from tensorflow-gpu==1.15->-r requirements.txt (line 1)) (1.1.2)
Requirement already satisfied: protobuf>=3.6.1 in ./venv/lib/python3.6/site-packages (from tensorflow-gpu==1.15->-r requirements.txt (line 1)) (3.18.0)
Requirement already satisfied: google-pasta>=0.1.6 in ./venv/lib/python3.6/site-packages (from tensorflow-gpu==1.15->-r requirements.txt (line 1)) (0.2.0)
Requirement already satisfied: tensorflow-estimator==1.15.1 in ./venv/lib/python3.6/site-packages (from tensorflow-gpu==1.15->-r requirements.txt (line 1)) (1.15.1)
Requirement already satisfied: termcolor>=1.1.0 in ./venv/lib/python3.6/site-packages (from tensorflow-gpu==1.15->-r requirements.txt (line 1)) (1.1.0)
Requirement already satisfied: wheel>=0.26 in ./venv/lib/python3.6/site-packages (from tensorflow-gpu==1.15->-r requirements.txt (line 1)) (0.37.0)
Requirement already satisfied: absl-py>=0.7.0 in ./venv/lib/python3.6/site-packages (from tensorflow-gpu==1.15->-r requirements.txt (line 1)) (0.14.1)
Requirement already satisfied: keras-applications>=1.0.8 in ./venv/lib/python3.6/site-packages (from tensorflow-gpu==1.15->-r requirements.txt (line 1)) (1.0.8)
Requirement already satisfied: numpy<2.0,>=1.16.0 in ./venv/lib/python3.6/site-packages (from tensorflow-gpu==1.15->-r requirements.txt (line 1)) (1.19.5)
Requirement already satisfied: grpcio>=1.8.6 in ./venv/lib/python3.6/site-packages (from tensorflow-gpu==1.15->-r requirements.txt (line 1)) (1.41.0)
Requirement already satisfied: gast==0.2.2 in ./venv/lib/python3.6/site-packages (from tensorflow-gpu==1.15->-r requirements.txt (line 1)) (0.2.2)
Requirement already satisfied: wrapt>=1.11.1 in ./venv/lib/python3.6/site-packages (from tensorflow-gpu==1.15->-r requirements.txt (line 1)) (1.12.1)
Requirement already satisfied: astor>=0.6.0 in ./venv/lib/python3.6/site-packages (from tensorflow-gpu==1.15->-r requirements.txt (line 1)) (0.8.1)
Requirement already satisfied: six>=1.10.0 in ./venv/lib/python3.6/site-packages (from tensorflow-gpu==1.15->-r requirements.txt (line 1)) (1.16.0)
Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in ./venv/lib/python3.6/site-packages (from tensorflow-gpu==1.15->-r requirements.txt (line 1)) (1.15.0)
Requirement already satisfied: opt-einsum>=2.3.2 in ./venv/lib/python3.6/site-packages (from tensorflow-gpu==1.15->-r requirements.txt (line 1)) (3.3.0)
Requirement already satisfied: decorator in ./venv/lib/python3.6/site-packages (from tensorflow-probability==0.7.0->-r requirements.txt (line 2)) (5.1.0)
Requirement already satisfied: cloudpickle>=0.6.1 in ./venv/lib/python3.6/site-packages (from tensorflow-probability==0.7.0->-r requirements.txt (line 2)) (2.0.0)
Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.6/site-packages (from matplotlib==3.1.0->-r requirements.txt (line 3)) (0.10.0)
Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in ./venv/lib/python3.6/site-packages (from matplotlib==3.1.0->-r requirements.txt (line 3)) (2.4.7)
Requirement already satisfied: kiwisolver>=1.0.1 in ./venv/lib/python3.6/site-packages (from matplotlib==3.1.0->-r requirements.txt (line 3)) (1.3.1)
Requirement already satisfied: python-dateutil>=2.1 in ./venv/lib/python3.6/site-packages (from matplotlib==3.1.0->-r requirements.txt (line 3)) (2.8.2)
Requirement already satisfied: param>=1.7.0 in ./venv/lib/python3.6/site-packages (from colorcet==2.0.1->-r requirements.txt (line 4)) (1.11.1)
Requirement already satisfied: pyct>=0.4.4 in ./venv/lib/python3.6/site-packages (from colorcet==2.0.1->-r requirements.txt (line 4)) (0.4.8)
Requirement already satisfied: munch<3.0,>=2.0.2 in ./venv/lib/python3.6/site-packages (from sacred==0.7.5->-r requirements.txt (line 6)) (2.5.0)
Requirement already satisfied: docopt<1.0,>=0.3 in ./venv/lib/python3.6/site-packages (from sacred==0.7.5->-r requirements.txt (line 6)) (0.6.2)
Requirement already satisfied: jsonpickle<1.0,>=0.7.2 in ./venv/lib/python3.6/site-packages (from sacred==0.7.5->-r requirements.txt (line 6)) (0.9.6)
Requirement already satisfied: colorama>=0.4 in ./venv/lib/python3.6/site-packages (from sacred==0.7.5->-r requirements.txt (line 6)) (0.4.4)
Requirement already satisfied: packaging>=18.0 in ./venv/lib/python3.6/site-packages (from sacred==0.7.5->-r requirements.txt (line 6)) (21.0)
Requirement already satisfied: py-cpuinfo>=4.0 in ./venv/lib/python3.6/site-packages (from sacred==0.7.5->-r requirements.txt (line 6)) (8.0.0)
Requirement already satisfied: h5py in ./venv/lib/python3.6/site-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15->-r requirements.txt (line 1)) (3.1.0)
Requirement already satisfied: markdown>=2.6.8 in ./venv/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15->-r requirements.txt (line 1)) (3.3.4)
Requirement already satisfied: setuptools>=41.0.0 in ./venv/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15->-r requirements.txt (line 1)) (58.2.0)
Requirement already satisfied: werkzeug>=0.11.15 in ./venv/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15->-r requirements.txt (line 1)) (2.0.1)
Requirement already satisfied: importlib-metadata in ./venv/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15->-r requirements.txt (line 1)) (4.8.1)
Requirement already satisfied: dataclasses in ./venv/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15->-r requirements.txt (line 1)) (0.8)
Requirement already satisfied: cached-property in ./venv/lib/python3.6/site-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==1.15->-r requirements.txt (line 1)) (1.5.2)
Requirement already satisfied: typing-extensions>=3.6.4 in ./venv/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15->-r requirements.txt (line 1)) (3.10.0.2)
Requirement already satisfied: zipp>=0.5 in ./venv/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15->-r requirements.txt (line 1)) (3.6.0)
loading data...
in get_train_data
getting model...
Model: "model"
_______________________________________________________________________________________________________________________________
Layer (type)                             Output Shape                Param #         Connected to                              
===============================================================================================================================
input_1 (InputLayer)                     [(None, 16, 32, 32, 1)]     0                                                         
_______________________________________________________________________________________________________________________________
conv3d (Conv3D)                          (None, 16, 32, 32, 16)      448             input_1[0][0]                             
_______________________________________________________________________________________________________________________________
group_normalization (GroupNormalization) (None, 16, 32, 32, 16)      32              conv3d[0][0]                              
_______________________________________________________________________________________________________________________________
conv3d_1 (Conv3D)                        (None, 16, 32, 32, 16)      6928            group_normalization[0][0]                 
_______________________________________________________________________________________________________________________________
group_normalization_1 (GroupNormalizatio (None, 16, 32, 32, 16)      32              conv3d_1[0][0]                            
_______________________________________________________________________________________________________________________________
max_pooling3d (MaxPooling3D)             (None, 8, 16, 16, 16)       0               group_normalization_1[0][0]               
_______________________________________________________________________________________________________________________________
conv3d_2 (Conv3D)                        (None, 8, 16, 16, 32)       13856           max_pooling3d[0][0]                       
_______________________________________________________________________________________________________________________________
group_normalization_2 (GroupNormalizatio (None, 8, 16, 16, 32)       64              conv3d_2[0][0]                            
_______________________________________________________________________________________________________________________________
conv3d_3 (Conv3D)                        (None, 8, 16, 16, 32)       27680           group_normalization_2[0][0]               
_______________________________________________________________________________________________________________________________
group_normalization_3 (GroupNormalizatio (None, 8, 16, 16, 32)       64              conv3d_3[0][0]                            
_______________________________________________________________________________________________________________________________
max_pooling3d_1 (MaxPooling3D)           (None, 4, 8, 8, 32)         0               group_normalization_3[0][0]               
_______________________________________________________________________________________________________________________________
conv3d_4 (Conv3D)                        (None, 4, 8, 8, 64)         55360           max_pooling3d_1[0][0]                     
_______________________________________________________________________________________________________________________________
group_normalization_4 (GroupNormalizatio (None, 4, 8, 8, 64)         128             conv3d_4[0][0]                            
_______________________________________________________________________________________________________________________________
conv3d_5 (Conv3D)                        (None, 4, 8, 8, 64)         110656          group_normalization_4[0][0]               
_______________________________________________________________________________________________________________________________
group_normalization_5 (GroupNormalizatio (None, 4, 8, 8, 64)         128             conv3d_5[0][0]                            
_______________________________________________________________________________________________________________________________
max_pooling3d_2 (MaxPooling3D)           (None, 2, 4, 4, 64)         0               group_normalization_5[0][0]               
_______________________________________________________________________________________________________________________________
conv3d_6 (Conv3D)                        (None, 2, 4, 4, 128)        221312          max_pooling3d_2[0][0]                     
_______________________________________________________________________________________________________________________________
group_normalization_6 (GroupNormalizatio (None, 2, 4, 4, 128)        256             conv3d_6[0][0]                            
_______________________________________________________________________________________________________________________________
conv3d_7 (Conv3D)                        (None, 2, 4, 4, 128)        442496          group_normalization_6[0][0]               
_______________________________________________________________________________________________________________________________
group_normalization_7 (GroupNormalizatio (None, 2, 4, 4, 128)        256             conv3d_7[0][0]                            
_______________________________________________________________________________________________________________________________
up_sampling3d (UpSampling3D)             (None, 4, 8, 8, 128)        0               group_normalization_7[0][0]               
_______________________________________________________________________________________________________________________________
conv3d_flipout (Conv3DFlipout)           (None, 4, 8, 8, 64)         131136          up_sampling3d[0][0]                       
_______________________________________________________________________________________________________________________________
group_normalization_8 (GroupNormalizatio (None, 4, 8, 8, 64)         128             conv3d_flipout[0][0]                      
_______________________________________________________________________________________________________________________________
concatenate (Concatenate)                (None, 4, 8, 8, 128)        0               group_normalization_5[0][0]               
                                                                                     group_normalization_8[0][0]               
_______________________________________________________________________________________________________________________________
group_normalization_9 (GroupNormalizatio (None, 4, 8, 8, 128)        256             concatenate[0][0]                         
_______________________________________________________________________________________________________________________________
conv3d_flipout_1 (Conv3DFlipout)         (None, 4, 8, 8, 64)         442432          group_normalization_9[0][0]               
_______________________________________________________________________________________________________________________________
group_normalization_10 (GroupNormalizati (None, 4, 8, 8, 64)         128             conv3d_flipout_1[0][0]                    
_______________________________________________________________________________________________________________________________
conv3d_flipout_2 (Conv3DFlipout)         (None, 4, 8, 8, 64)         221248          group_normalization_10[0][0]              
_______________________________________________________________________________________________________________________________
group_normalization_11 (GroupNormalizati (None, 4, 8, 8, 64)         128             conv3d_flipout_2[0][0]                    
_______________________________________________________________________________________________________________________________
up_sampling3d_1 (UpSampling3D)           (None, 8, 16, 16, 64)       0               group_normalization_11[0][0]              
_______________________________________________________________________________________________________________________________
conv3d_flipout_3 (Conv3DFlipout)         (None, 8, 16, 16, 32)       32800           up_sampling3d_1[0][0]                     
_______________________________________________________________________________________________________________________________
group_normalization_12 (GroupNormalizati (None, 8, 16, 16, 32)       64              conv3d_flipout_3[0][0]                    
_______________________________________________________________________________________________________________________________
concatenate_1 (Concatenate)              (None, 8, 16, 16, 64)       0               group_normalization_3[0][0]               
                                                                                     group_normalization_12[0][0]              
_______________________________________________________________________________________________________________________________
group_normalization_13 (GroupNormalizati (None, 8, 16, 16, 64)       128             concatenate_1[0][0]                       
_______________________________________________________________________________________________________________________________
conv3d_flipout_4 (Conv3DFlipout)         (None, 8, 16, 16, 32)       110624          group_normalization_13[0][0]              
_______________________________________________________________________________________________________________________________
group_normalization_14 (GroupNormalizati (None, 8, 16, 16, 32)       64              conv3d_flipout_4[0][0]                    
_______________________________________________________________________________________________________________________________
conv3d_flipout_5 (Conv3DFlipout)         (None, 8, 16, 16, 32)       55328           group_normalization_14[0][0]              
_______________________________________________________________________________________________________________________________
group_normalization_15 (GroupNormalizati (None, 8, 16, 16, 32)       64              conv3d_flipout_5[0][0]                    
_______________________________________________________________________________________________________________________________
up_sampling3d_2 (UpSampling3D)           (None, 16, 32, 32, 32)      0               group_normalization_15[0][0]              
_______________________________________________________________________________________________________________________________
conv3d_flipout_6 (Conv3DFlipout)         (None, 16, 32, 32, 16)      8208            up_sampling3d_2[0][0]                     
_______________________________________________________________________________________________________________________________
group_normalization_16 (GroupNormalizati (None, 16, 32, 32, 16)      32              conv3d_flipout_6[0][0]                    
_______________________________________________________________________________________________________________________________
concatenate_2 (Concatenate)              (None, 16, 32, 32, 32)      0               group_normalization_1[0][0]               
                                                                                     group_normalization_16[0][0]              
_______________________________________________________________________________________________________________________________
group_normalization_17 (GroupNormalizati (None, 16, 32, 32, 32)      64              concatenate_2[0][0]                       
_______________________________________________________________________________________________________________________________
conv3d_flipout_7 (Conv3DFlipout)         (None, 16, 32, 32, 16)      27664           group_normalization_17[0][0]              
_______________________________________________________________________________________________________________________________
group_normalization_18 (GroupNormalizati (None, 16, 32, 32, 16)      32              conv3d_flipout_7[0][0]                    
_______________________________________________________________________________________________________________________________
conv3d_flipout_8 (Conv3DFlipout)         (None, 16, 32, 32, 16)      13840           group_normalization_18[0][0]              
_______________________________________________________________________________________________________________________________
group_normalization_19 (GroupNormalizati (None, 16, 32, 32, 16)      32              conv3d_flipout_8[0][0]                    
_______________________________________________________________________________________________________________________________
conv3d_flipout_9 (Conv3DFlipout)         (None, 16, 32, 32, 1)       865             group_normalization_19[0][0]              
_______________________________________________________________________________________________________________________________
conv3d_flipout_10 (Conv3DFlipout)        (None, 16, 32, 32, 1)       3               conv3d_flipout_9[0][0]                    
===============================================================================================================================
Total params: 1,924,964
Trainable params: 1,924,964
Non-trainable params: 0
_______________________________________________________________________________________________________________________________
<class 'float'> <class 'tensorflow.python.keras.engine.training.Model'> <class 'tensorflow.python.framework.ops.Tensor'>
fitting model...
Train on 313 samples, validate on 313 samples
Epoch 1/10
 16/313 [>.............................] - ETA: 5:15 - loss: 1320807.3750 - acc: 0.4699 32/313 [==>...........................] - ETA: 4:28 - loss: 1320532.6250 - acc: 0.5495 48/313 [===>..........................] - ETA: 4:02 - loss: 1320258.1250 - acc: 0.5574 64/313 [=====>........................] - ETA: 3:43 - loss: 1319983.7188 - acc: 0.5797 80/313 [======>.......................] - ETA: 3:26 - loss: 1319709.5250 - acc: 0.5870 96/313 [========>.....................] - ETA: 3:10 - loss: 1319435.5208 - acc: 0.6082112/313 [=========>....................] - ETA: 2:55 - loss: 1319161.6786 - acc: 0.6156128/313 [===========>..................] - ETA: 2:40 - loss: 1318888.0469 - acc: 0.6258144/313 [============>.................] - ETA: 2:26 - loss: 1318614.5972 - acc: 0.6437160/313 [==============>...............] - ETA: 2:12 - loss: 1318341.3375 - acc: 0.6598176/313 [===============>..............] - ETA: 1:57 - loss: 1318068.2614 - acc: 0.6775192/313 [=================>............] - ETA: 1:43 - loss: 1317795.3854 - acc: 0.6916208/313 [==================>...........] - ETA: 1:29 - loss: 1317522.6827 - acc: 0.6966224/313 [====================>.........] - ETA: 1:16 - loss: 1317250.1607 - acc: 0.7075240/313 [======================>.......] - ETA: 1:02 - loss: 1316977.8250 - acc: 0.7185256/313 [=======================>......] - ETA: 48s - loss: 1316705.6797 - acc: 0.7288 272/313 [=========================>....] - ETA: 34s - loss: 1316433.7059 - acc: 0.7377288/313 [==========================>...] - ETA: 21s - loss: 1316161.9236 - acc: 0.7481304/313 [============================>.] - ETA: 7s - loss: 1315890.3158 - acc: 0.7581 
Epoch 00001: val_loss improved from inf to 1309922.62500, saving model to weights/bayesian/bayesian-01-0.936-1309923.h5
Current KL Weight is 0.5
313/313 [==============================] - 323s 1s/sample - loss: 1315734.2192 - acc: 0.7622 - val_loss: 1309922.6250 - val_acc: 0.9357
Epoch 2/10
 16/313 [>.............................] - ETA: 4:08 - loss: 1309922.6250 - acc: 0.9385 32/313 [==>...........................] - ETA: 3:55 - loss: 1309653.3750 - acc: 0.9363 48/313 [===>..........................] - ETA: 3:41 - loss: 1309384.2917 - acc: 0.9382 64/313 [=====>........................] - ETA: 3:28 - loss: 1309115.3750 - acc: 0.9428 80/313 [======>.......................] - ETA: 3:14 - loss: 1308846.6000 - acc: 0.9444 96/313 [========>.....................] - ETA: 3:01 - loss: 1308578.0208 - acc: 0.9469112/313 [=========>....................] - ETA: 2:48 - loss: 1308309.5893 - acc: 0.9480128/313 [===========>..................] - ETA: 2:34 - loss: 1308041.3125 - acc: 0.9519144/313 [============>.................] - ETA: 2:21 - loss: 1307773.1944 - acc: 0.9544160/313 [==============>...............] - ETA: 2:08 - loss: 1307505.2500 - acc: 0.9551176/313 [===============>..............] - ETA: 1:54 - loss: 1307237.4773 - acc: 0.9569192/313 [=================>............] - ETA: 1:41 - loss: 1306969.8542 - acc: 0.9595208/313 [==================>...........] - ETA: 1:27 - loss: 1306702.3942 - acc: 0.9611224/313 [====================>.........] - ETA: 1:14 - loss: 1306435.0982 - acc: 0.9620240/313 [======================>.......] - ETA: 1:01 - loss: 1306167.9583 - acc: 0.9629256/313 [=======================>......] - ETA: 47s - loss: 1305900.9688 - acc: 0.9641 272/313 [=========================>....] - ETA: 34s - loss: 1305634.1324 - acc: 0.9653288/313 [==========================>...] - ETA: 20s - loss: 1305367.4444 - acc: 0.9666304/313 [============================>.] - ETA: 7s - loss: 1305100.9079 - acc: 0.9678 
Epoch 00002: val_loss improved from 1309922.62500 to 1299243.50000, saving model to weights/bayesian/bayesian-02-0.989-1299244.h5
Current KL Weight is 1.0
313/313 [==============================] - 312s 997ms/sample - loss: 1304947.7093 - acc: 0.9682 - val_loss: 1299243.5000 - val_acc: 0.9893
Epoch 3/10
 16/313 [>.............................] - ETA: 4:09 - loss: 1299243.5000 - acc: 0.9936 32/313 [==>...........................] - ETA: 3:54 - loss: 1298978.7500 - acc: 0.9947 48/313 [===>..........................] - ETA: 3:41 - loss: 1298714.1667 - acc: 0.9939 64/313 [=====>........................] - ETA: 3:28 - loss: 1298449.7500 - acc: 0.9945 80/313 [======>.......................] - ETA: 3:15 - loss: 1298185.4500 - acc: 0.9948 96/313 [========>.....................] - ETA: 3:01 - loss: 1297921.2917 - acc: 0.9945112/313 [=========>....................] - ETA: 2:48 - loss: 1297657.2500 - acc: 0.9951128/313 [===========>..................] - ETA: 2:34 - loss: 1297393.3438 - acc: 0.9953144/313 [============>.................] - ETA: 2:21 - loss: 1297129.5556 - acc: 0.9946160/313 [==============>...............] - ETA: 2:08 - loss: 1296865.9000 - acc: 0.9944176/313 [===============>..............] - ETA: 1:54 - loss: 1296602.3636 - acc: 0.9938192/313 [=================>............] - ETA: 1:40 - loss: 1296338.9375 - acc: 0.9933208/313 [==================>...........] - ETA: 1:27 - loss: 1296075.6058 - acc: 0.9938224/313 [====================>.........] - ETA: 1:13 - loss: 1295812.4196 - acc: 0.9939240/313 [======================>.......] - ETA: 1:00 - loss: 1295549.3333 - acc: 0.9942256/313 [=======================>......] - ETA: 46s - loss: 1295286.3672 - acc: 0.9944 272/313 [=========================>....] - ETA: 33s - loss: 1295023.5221 - acc: 0.9943288/313 [==========================>...] - ETA: 20s - loss: 1294760.7778 - acc: 0.9945304/313 [============================>.] - ETA: 7s - loss: 1294498.1250 - acc: 0.9947 
Epoch 00003: val_loss improved from 1299243.50000 to 1288724.67612, saving model to weights/bayesian/bayesian-03-0.996-1288725.h5
Current KL Weight is 1.0
313/313 [==============================] - 307s 980ms/sample - loss: 1294347.1486 - acc: 0.9949 - val_loss: 1288724.6761 - val_acc: 0.9964
Epoch 4/10
 16/313 [>.............................] - ETA: 4:08 - loss: 1288724.6250 - acc: 0.9983 32/313 [==>...........................] - ETA: 3:55 - loss: 1288463.3750 - acc: 0.9988 48/313 [===>..........................] - ETA: 3:41 - loss: 1288202.1250 - acc: 0.9976 64/313 [=====>........................] - ETA: 3:28 - loss: 1287941.0312 - acc: 0.9982 80/313 [======>.......................] - ETA: 3:14 - loss: 1287680.0250 - acc: 0.9986 96/313 [========>.....................] - ETA: 3:01 - loss: 1287419.1458 - acc: 0.9988112/313 [=========>....................] - ETA: 2:47 - loss: 1287158.3214 - acc: 0.9990128/313 [===========>..................] - ETA: 2:34 - loss: 1286897.5781 - acc: 0.9991144/313 [============>.................] - ETA: 2:21 - loss: 1286636.9306 - acc: 0.9992160/313 [==============>...............] - ETA: 2:07 - loss: 1286376.3750 - acc: 0.9993176/313 [===============>..............] - ETA: 1:54 - loss: 1286115.8977 - acc: 0.9993192/313 [=================>............] - ETA: 1:41 - loss: 1285855.5208 - acc: 0.9994208/313 [==================>...........] - ETA: 1:27 - loss: 1285595.2115 - acc: 0.9994224/313 [====================>.........] - ETA: 1:14 - loss: 1285334.9911 - acc: 0.9995240/313 [======================>.......] - ETA: 1:01 - loss: 1285074.8583 - acc: 0.9995256/313 [=======================>......] - ETA: 47s - loss: 1284814.7969 - acc: 0.9996 272/313 [=========================>....] - ETA: 34s - loss: 1284554.8088 - acc: 0.9996288/313 [==========================>...] - ETA: 20s - loss: 1284294.9097 - acc: 0.9996304/313 [============================>.] - ETA: 7s - loss: 1284035.0921 - acc: 0.9996 
Epoch 00004: val_loss improved from 1288724.67612 to 1278322.37500, saving model to weights/bayesian/bayesian-04-1.000-1278322.h5
Current KL Weight is 1.0
313/313 [==============================] - 311s 995ms/sample - loss: 1283885.7232 - acc: 0.9996 - val_loss: 1278322.3750 - val_acc: 1.0000
Epoch 5/10
 16/313 [>.............................] - ETA: 4:08 - loss: 1278322.3750 - acc: 1.0000 32/313 [==>...........................] - ETA: 3:52 - loss: 1278063.5000 - acc: 1.0000 48/313 [===>..........................] - ETA: 3:36 - loss: 1277804.7083 - acc: 1.0000 64/313 [=====>........................] - ETA: 3:22 - loss: 1277546.0000 - acc: 1.0000 80/313 [======>.......................] - ETA: 3:08 - loss: 1277287.3750 - acc: 1.0000 96/313 [========>.....................] - ETA: 2:54 - loss: 1277028.8125 - acc: 1.0000112/313 [=========>....................] - ETA: 2:41 - loss: 1276770.3214 - acc: 1.0000128/313 [===========>..................] - ETA: 2:29 - loss: 1276511.8750 - acc: 1.0000144/313 [============>.................] - ETA: 2:16 - loss: 1276253.5000 - acc: 1.0000160/313 [==============>...............] - ETA: 2:04 - loss: 1275995.1875 - acc: 1.0000176/313 [===============>..............] - ETA: 1:51 - loss: 1275736.9318 - acc: 1.0000192/313 [=================>............] - ETA: 1:38 - loss: 1275478.7396 - acc: 1.0000208/313 [==================>...........] - ETA: 1:25 - loss: 1275220.6154 - acc: 1.0000224/313 [====================>.........] - ETA: 1:12 - loss: 1274962.5625 - acc: 1.0000240/313 [======================>.......] - ETA: 59s - loss: 1274704.5583 - acc: 1.0000 256/313 [=======================>......] - ETA: 46s - loss: 1274446.6094 - acc: 1.0000272/313 [=========================>....] - ETA: 33s - loss: 1274188.7279 - acc: 1.0000288/313 [==========================>...] - ETA: 20s - loss: 1273930.8958 - acc: 1.0000304/313 [============================>.] - ETA: 7s - loss: 1273673.1250 - acc: 1.0000 
Epoch 00005: val_loss improved from 1278322.37500 to 1268004.62500, saving model to weights/bayesian/bayesian-05-1.000-1268005.h5
Current KL Weight is 1.0
313/313 [==============================] - 308s 983ms/sample - loss: 1273524.9197 - acc: 1.0000 - val_loss: 1268004.6250 - val_acc: 1.0000
Epoch 6/10
 16/313 [>.............................] - ETA: 4:07 - loss: 1268004.6250 - acc: 1.0000 32/313 [==>...........................] - ETA: 3:54 - loss: 1267747.5625 - acc: 1.0000 48/313 [===>..........................] - ETA: 3:41 - loss: 1267490.5417 - acc: 1.0000 64/313 [=====>........................] - ETA: 3:27 - loss: 1267233.6250 - acc: 1.0000 80/313 [======>.......................] - ETA: 3:14 - loss: 1266976.7250 - acc: 1.0000 96/313 [========>.....................] - ETA: 3:01 - loss: 1266719.8750 - acc: 1.0000112/313 [=========>....................] - ETA: 2:47 - loss: 1266463.0714 - acc: 1.0000128/313 [===========>..................] - ETA: 2:34 - loss: 1266206.3281 - acc: 1.0000144/313 [============>.................] - ETA: 2:20 - loss: 1265949.6389 - acc: 1.0000160/313 [==============>...............] - ETA: 2:07 - loss: 1265692.9875 - acc: 1.0000176/313 [===============>..............] - ETA: 1:54 - loss: 1265436.3864 - acc: 1.0000192/313 [=================>............] - ETA: 1:40 - loss: 1265179.8229 - acc: 1.0000208/313 [==================>...........] - ETA: 1:27 - loss: 1264923.3077 - acc: 1.0000224/313 [====================>.........] - ETA: 1:14 - loss: 1264666.8482 - acc: 1.0000240/313 [======================>.......] - ETA: 1:00 - loss: 1264410.4333 - acc: 1.0000256/313 [=======================>......] - ETA: 47s - loss: 1264154.0625 - acc: 1.0000 272/313 [=========================>....] - ETA: 34s - loss: 1263897.7353 - acc: 1.0000288/313 [==========================>...] - ETA: 20s - loss: 1263641.4375 - acc: 1.0000304/313 [============================>.] - ETA: 7s - loss: 1263385.1908 - acc: 1.0000 
Epoch 00006: val_loss improved from 1268004.62500 to 1257749.62500, saving model to weights/bayesian/bayesian-06-1.000-1257750.h5
Current KL Weight is 1.0
313/313 [==============================] - 311s 995ms/sample - loss: 1263237.8534 - acc: 1.0000 - val_loss: 1257749.6250 - val_acc: 1.0000
Epoch 7/10
 16/313 [>.............................] - ETA: 4:08 - loss: 1257749.6250 - acc: 1.0000 32/313 [==>...........................] - ETA: 3:55 - loss: 1257493.8750 - acc: 1.0000 48/313 [===>..........................] - ETA: 3:41 - loss: 1257238.2083 - acc: 1.0000 64/313 [=====>........................] - ETA: 3:27 - loss: 1256982.5625 - acc: 1.0000 80/313 [======>.......................] - ETA: 3:13 - loss: 1256727.0000 - acc: 1.0000 96/313 [========>.....................] - ETA: 3:00 - loss: 1256471.4583 - acc: 1.0000112/313 [=========>....................] - ETA: 2:47 - loss: 1256215.9464 - acc: 1.0000128/313 [===========>..................] - ETA: 2:34 - loss: 1255960.5000 - acc: 1.0000144/313 [============>.................] - ETA: 2:20 - loss: 1255705.0694 - acc: 1.0000160/313 [==============>...............] - ETA: 2:07 - loss: 1255449.6750 - acc: 1.0000176/313 [===============>..............] - ETA: 1:54 - loss: 1255194.3068 - acc: 1.0000192/313 [=================>............] - ETA: 1:40 - loss: 1254938.9896 - acc: 1.0000208/313 [==================>...........] - ETA: 1:27 - loss: 1254683.7019 - acc: 1.0000224/313 [====================>.........] - ETA: 1:14 - loss: 1254428.4464 - acc: 1.0000240/313 [======================>.......] - ETA: 1:00 - loss: 1254173.2333 - acc: 1.0000256/313 [=======================>......] - ETA: 47s - loss: 1253918.0547 - acc: 1.0000 272/313 [=========================>....] - ETA: 34s - loss: 1253662.9118 - acc: 1.0000288/313 [==========================>...] - ETA: 20s - loss: 1253407.7986 - acc: 1.0000304/313 [============================>.] - ETA: 7s - loss: 1253152.7237 - acc: 1.0000 
Epoch 00007: val_loss improved from 1257749.62500 to 1247542.37500, saving model to weights/bayesian/bayesian-07-1.000-1247542.h5
Current KL Weight is 1.0
313/313 [==============================] - 311s 994ms/sample - loss: 1253006.0539 - acc: 1.0000 - val_loss: 1247542.3750 - val_acc: 1.0000
Epoch 8/10
 16/313 [>.............................] - ETA: 4:05 - loss: 1247542.3750 - acc: 1.0000 32/313 [==>...........................] - ETA: 3:47 - loss: 1247287.7500 - acc: 1.0000 48/313 [===>..........................] - ETA: 3:33 - loss: 1247033.1250 - acc: 1.0000 64/313 [=====>........................] - ETA: 3:19 - loss: 1246778.5312 - acc: 1.0000 80/313 [======>.......................] - ETA: 3:06 - loss: 1246523.9500 - acc: 1.0000 96/313 [========>.....................] - ETA: 2:53 - loss: 1246269.4167 - acc: 1.0000112/313 [=========>....................] - ETA: 2:40 - loss: 1246014.9107 - acc: 1.0000128/313 [===========>..................] - ETA: 2:27 - loss: 1245760.4375 - acc: 1.0000144/313 [============>.................] - ETA: 2:14 - loss: 1245505.9861 - acc: 1.0000160/313 [==============>...............] - ETA: 2:01 - loss: 1245251.5625 - acc: 1.0000176/313 [===============>..............] - ETA: 1:49 - loss: 1244997.1818 - acc: 1.0000192/313 [=================>............] - ETA: 1:36 - loss: 1244742.8333 - acc: 1.0000208/313 [==================>...........] - ETA: 1:23 - loss: 1244488.5000 - acc: 1.0000224/313 [====================>.........] - ETA: 1:10 - loss: 1244234.1964 - acc: 1.0000240/313 [======================>.......] - ETA: 58s - loss: 1243979.9167 - acc: 1.0000 256/313 [=======================>......] - ETA: 45s - loss: 1243725.6641 - acc: 1.0000272/313 [=========================>....] - ETA: 32s - loss: 1243471.4412 - acc: 1.0000288/313 [==========================>...] - ETA: 19s - loss: 1243217.2431 - acc: 1.0000304/313 [============================>.] - ETA: 7s - loss: 1242963.0789 - acc: 1.0000 
Epoch 00008: val_loss improved from 1247542.37500 to 1237372.62500, saving model to weights/bayesian/bayesian-08-1.000-1237373.h5
Current KL Weight is 1.0
313/313 [==============================] - 296s 945ms/sample - loss: 1242816.9309 - acc: 1.0000 - val_loss: 1237372.6250 - val_acc: 1.0000
Epoch 9/10
 16/313 [>.............................] - ETA: 3:58 - loss: 1237372.6250 - acc: 1.0000 32/313 [==>...........................] - ETA: 3:45 - loss: 1237118.7500 - acc: 1.0000 48/313 [===>..........................] - ETA: 3:32 - loss: 1236864.9583 - acc: 1.0000 64/313 [=====>........................] - ETA: 3:19 - loss: 1236611.1562 - acc: 1.0000 80/313 [======>.......................] - ETA: 3:08 - loss: 1236357.4000 - acc: 1.0000 96/313 [========>.....................] - ETA: 2:56 - loss: 1236103.6458 - acc: 1.0000112/313 [=========>....................] - ETA: 2:43 - loss: 1235849.9464 - acc: 1.0000128/313 [===========>..................] - ETA: 2:31 - loss: 1235596.2500 - acc: 1.0000144/313 [============>.................] - ETA: 2:18 - loss: 1235342.5972 - acc: 1.0000160/313 [==============>...............] - ETA: 2:05 - loss: 1235088.9750 - acc: 1.0000176/313 [===============>..............] - ETA: 1:52 - loss: 1234835.3636 - acc: 1.0000192/313 [=================>............] - ETA: 1:39 - loss: 1234581.7812 - acc: 1.0000208/313 [==================>...........] - ETA: 1:26 - loss: 1234328.2115 - acc: 1.0000224/313 [====================>.........] - ETA: 1:13 - loss: 1234074.6696 - acc: 1.0000240/313 [======================>.......] - ETA: 1:00 - loss: 1233821.1500 - acc: 1.0000256/313 [=======================>......] - ETA: 47s - loss: 1233567.6484 - acc: 1.0000 272/313 [=========================>....] - ETA: 33s - loss: 1233314.1691 - acc: 1.0000288/313 [==========================>...] - ETA: 20s - loss: 1233060.7153 - acc: 1.0000304/313 [============================>.] - ETA: 7s - loss: 1232807.2829 - acc: 1.0000 
Epoch 00009: val_loss improved from 1237372.62500 to 1227232.62500, saving model to weights/bayesian/bayesian-09-1.000-1227233.h5
Current KL Weight is 1.0
313/313 [==============================] - 309s 986ms/sample - loss: 1232661.5495 - acc: 1.0000 - val_loss: 1227232.6250 - val_acc: 1.0000
Epoch 10/10
 16/313 [>.............................] - ETA: 4:08 - loss: 1227232.6250 - acc: 1.0000 32/313 [==>...........................] - ETA: 3:55 - loss: 1226979.5000 - acc: 1.0000 48/313 [===>..........................] - ETA: 3:40 - loss: 1226726.3750 - acc: 1.0000 64/313 [=====>........................] - ETA: 3:26 - loss: 1226473.2500 - acc: 1.0000 80/313 [======>.......................] - ETA: 3:12 - loss: 1226220.1750 - acc: 1.0000 96/313 [========>.....................] - ETA: 2:57 - loss: 1225967.1250 - acc: 1.0000112/313 [=========>....................] - ETA: 2:43 - loss: 1225714.0893 - acc: 1.0000128/313 [===========>..................] - ETA: 2:30 - loss: 1225461.0625 - acc: 1.0000144/313 [============>.................] - ETA: 2:18 - loss: 1225208.0417 - acc: 1.0000160/313 [==============>...............] - ETA: 2:05 - loss: 1224955.0500 - acc: 1.0000176/313 [===============>..............] - ETA: 1:52 - loss: 1224702.0795 - acc: 1.0000192/313 [=================>............] - ETA: 1:39 - loss: 1224449.1250 - acc: 1.0000208/313 [==================>...........] - ETA: 1:25 - loss: 1224196.1827 - acc: 1.0000224/313 [====================>.........] - ETA: 1:12 - loss: 1223943.2679 - acc: 1.0000240/313 [======================>.......] - ETA: 59s - loss: 1223690.3750 - acc: 1.0000 256/313 [=======================>......] - ETA: 46s - loss: 1223437.5000 - acc: 1.0000272/313 [=========================>....] - ETA: 33s - loss: 1223184.6397 - acc: 1.0000288/313 [==========================>...] - ETA: 20s - loss: 1222931.7917 - acc: 1.0000304/313 [============================>.] - ETA: 7s - loss: 1222678.9671 - acc: 1.0000 
Epoch 00010: val_loss improved from 1227232.62500 to 1217117.62500, saving model to weights/bayesian/bayesian-10-1.000-1217118.h5
Current KL Weight is 1.0
313/313 [==============================] - 303s 969ms/sample - loss: 1222533.5843 - acc: 1.0000 - val_loss: 1217117.6250 - val_acc: 1.0000
