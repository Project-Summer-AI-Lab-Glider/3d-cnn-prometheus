p2299
Defaulting to user installation because normal site-packages is not writeable
loading data...
in get_train_data
getting model...
Model: "model"
_______________________________________________________________________________________________________________________________
Layer (type)                             Output Shape                Param #         Connected to                              
===============================================================================================================================
input_1 (InputLayer)                     [(None, 16, 32, 32, 1)]     0                                                         
_______________________________________________________________________________________________________________________________
conv3d (Conv3D)                          (None, 16, 32, 32, 16)      448             input_1[0][0]                             
_______________________________________________________________________________________________________________________________
group_normalization (GroupNormalization) (None, 16, 32, 32, 16)      32              conv3d[0][0]                              
_______________________________________________________________________________________________________________________________
conv3d_1 (Conv3D)                        (None, 16, 32, 32, 16)      6928            group_normalization[0][0]                 
_______________________________________________________________________________________________________________________________
group_normalization_1 (GroupNormalizatio (None, 16, 32, 32, 16)      32              conv3d_1[0][0]                            
_______________________________________________________________________________________________________________________________
max_pooling3d (MaxPooling3D)             (None, 8, 16, 16, 16)       0               group_normalization_1[0][0]               
_______________________________________________________________________________________________________________________________
conv3d_2 (Conv3D)                        (None, 8, 16, 16, 32)       13856           max_pooling3d[0][0]                       
_______________________________________________________________________________________________________________________________
group_normalization_2 (GroupNormalizatio (None, 8, 16, 16, 32)       64              conv3d_2[0][0]                            
_______________________________________________________________________________________________________________________________
conv3d_3 (Conv3D)                        (None, 8, 16, 16, 32)       27680           group_normalization_2[0][0]               
_______________________________________________________________________________________________________________________________
group_normalization_3 (GroupNormalizatio (None, 8, 16, 16, 32)       64              conv3d_3[0][0]                            
_______________________________________________________________________________________________________________________________
max_pooling3d_1 (MaxPooling3D)           (None, 4, 8, 8, 32)         0               group_normalization_3[0][0]               
_______________________________________________________________________________________________________________________________
conv3d_4 (Conv3D)                        (None, 4, 8, 8, 64)         55360           max_pooling3d_1[0][0]                     
_______________________________________________________________________________________________________________________________
group_normalization_4 (GroupNormalizatio (None, 4, 8, 8, 64)         128             conv3d_4[0][0]                            
_______________________________________________________________________________________________________________________________
conv3d_5 (Conv3D)                        (None, 4, 8, 8, 64)         110656          group_normalization_4[0][0]               
_______________________________________________________________________________________________________________________________
group_normalization_5 (GroupNormalizatio (None, 4, 8, 8, 64)         128             conv3d_5[0][0]                            
_______________________________________________________________________________________________________________________________
max_pooling3d_2 (MaxPooling3D)           (None, 2, 4, 4, 64)         0               group_normalization_5[0][0]               
_______________________________________________________________________________________________________________________________
conv3d_6 (Conv3D)                        (None, 2, 4, 4, 128)        221312          max_pooling3d_2[0][0]                     
_______________________________________________________________________________________________________________________________
group_normalization_6 (GroupNormalizatio (None, 2, 4, 4, 128)        256             conv3d_6[0][0]                            
_______________________________________________________________________________________________________________________________
conv3d_7 (Conv3D)                        (None, 2, 4, 4, 128)        442496          group_normalization_6[0][0]               
_______________________________________________________________________________________________________________________________
group_normalization_7 (GroupNormalizatio (None, 2, 4, 4, 128)        256             conv3d_7[0][0]                            
_______________________________________________________________________________________________________________________________
up_sampling3d (UpSampling3D)             (None, 4, 8, 8, 128)        0               group_normalization_7[0][0]               
_______________________________________________________________________________________________________________________________
conv3d_flipout (Conv3DFlipout)           (None, 4, 8, 8, 64)         131136          up_sampling3d[0][0]                       
_______________________________________________________________________________________________________________________________
group_normalization_8 (GroupNormalizatio (None, 4, 8, 8, 64)         128             conv3d_flipout[0][0]                      
_______________________________________________________________________________________________________________________________
concatenate (Concatenate)                (None, 4, 8, 8, 128)        0               group_normalization_5[0][0]               
                                                                                     group_normalization_8[0][0]               
_______________________________________________________________________________________________________________________________
group_normalization_9 (GroupNormalizatio (None, 4, 8, 8, 128)        256             concatenate[0][0]                         
_______________________________________________________________________________________________________________________________
conv3d_flipout_1 (Conv3DFlipout)         (None, 4, 8, 8, 64)         442432          group_normalization_9[0][0]               
_______________________________________________________________________________________________________________________________
group_normalization_10 (GroupNormalizati (None, 4, 8, 8, 64)         128             conv3d_flipout_1[0][0]                    
_______________________________________________________________________________________________________________________________
conv3d_flipout_2 (Conv3DFlipout)         (None, 4, 8, 8, 64)         221248          group_normalization_10[0][0]              
_______________________________________________________________________________________________________________________________
group_normalization_11 (GroupNormalizati (None, 4, 8, 8, 64)         128             conv3d_flipout_2[0][0]                    
_______________________________________________________________________________________________________________________________
up_sampling3d_1 (UpSampling3D)           (None, 8, 16, 16, 64)       0               group_normalization_11[0][0]              
_______________________________________________________________________________________________________________________________
conv3d_flipout_3 (Conv3DFlipout)         (None, 8, 16, 16, 32)       32800           up_sampling3d_1[0][0]                     
_______________________________________________________________________________________________________________________________
group_normalization_12 (GroupNormalizati (None, 8, 16, 16, 32)       64              conv3d_flipout_3[0][0]                    
_______________________________________________________________________________________________________________________________
concatenate_1 (Concatenate)              (None, 8, 16, 16, 64)       0               group_normalization_3[0][0]               
                                                                                     group_normalization_12[0][0]              
_______________________________________________________________________________________________________________________________
group_normalization_13 (GroupNormalizati (None, 8, 16, 16, 64)       128             concatenate_1[0][0]                       
_______________________________________________________________________________________________________________________________
conv3d_flipout_4 (Conv3DFlipout)         (None, 8, 16, 16, 32)       110624          group_normalization_13[0][0]              
_______________________________________________________________________________________________________________________________
group_normalization_14 (GroupNormalizati (None, 8, 16, 16, 32)       64              conv3d_flipout_4[0][0]                    
_______________________________________________________________________________________________________________________________
conv3d_flipout_5 (Conv3DFlipout)         (None, 8, 16, 16, 32)       55328           group_normalization_14[0][0]              
_______________________________________________________________________________________________________________________________
group_normalization_15 (GroupNormalizati (None, 8, 16, 16, 32)       64              conv3d_flipout_5[0][0]                    
_______________________________________________________________________________________________________________________________
up_sampling3d_2 (UpSampling3D)           (None, 16, 32, 32, 32)      0               group_normalization_15[0][0]              
_______________________________________________________________________________________________________________________________
conv3d_flipout_6 (Conv3DFlipout)         (None, 16, 32, 32, 16)      8208            up_sampling3d_2[0][0]                     
_______________________________________________________________________________________________________________________________
group_normalization_16 (GroupNormalizati (None, 16, 32, 32, 16)      32              conv3d_flipout_6[0][0]                    
_______________________________________________________________________________________________________________________________
concatenate_2 (Concatenate)              (None, 16, 32, 32, 32)      0               group_normalization_1[0][0]               
                                                                                     group_normalization_16[0][0]              
_______________________________________________________________________________________________________________________________
group_normalization_17 (GroupNormalizati (None, 16, 32, 32, 32)      64              concatenate_2[0][0]                       
_______________________________________________________________________________________________________________________________
conv3d_flipout_7 (Conv3DFlipout)         (None, 16, 32, 32, 16)      27664           group_normalization_17[0][0]              
_______________________________________________________________________________________________________________________________
group_normalization_18 (GroupNormalizati (None, 16, 32, 32, 16)      32              conv3d_flipout_7[0][0]                    
_______________________________________________________________________________________________________________________________
conv3d_flipout_8 (Conv3DFlipout)         (None, 16, 32, 32, 16)      13840           group_normalization_18[0][0]              
_______________________________________________________________________________________________________________________________
group_normalization_19 (GroupNormalizati (None, 16, 32, 32, 16)      32              conv3d_flipout_8[0][0]                    
_______________________________________________________________________________________________________________________________
conv3d_flipout_9 (Conv3DFlipout)         (None, 16, 32, 32, 1)       865             group_normalization_19[0][0]              
_______________________________________________________________________________________________________________________________
conv3d_flipout_10 (Conv3DFlipout)        (None, 16, 32, 32, 1)       3               conv3d_flipout_9[0][0]                    
===============================================================================================================================
Total params: 1,924,964
Trainable params: 1,924,964
Non-trainable params: 0
_______________________________________________________________________________________________________________________________
<class 'float'> <class 'keras.engine.functional.Functional'> <class 'tensorflow.python.framework.ops.Tensor'>
fitting model...
Epoch 1/5
 1/20 [>.............................] - ETA: 4:01 - loss: 1320678.5000 - accuracy: 0.0901 2/20 [==>...........................] - ETA: 7s - loss: 1320403.7500 - accuracy: 0.1604   3/20 [===>..........................] - ETA: 7s - loss: 1320129.1250 - accuracy: 0.1845 4/20 [=====>........................] - ETA: 6s - loss: 1319854.6250 - accuracy: 0.2054 5/20 [======>.......................] - ETA: 6s - loss: 1319580.3750 - accuracy: 0.2128 6/20 [========>.....................] - ETA: 6s - loss: 1319306.3750 - accuracy: 0.2342 7/20 [=========>....................] - ETA: 5s - loss: 1319032.6250 - accuracy: 0.2452 8/20 [===========>..................] - ETA: 5s - loss: 1318758.8750 - accuracy: 0.2650 9/20 [============>.................] - ETA: 4s - loss: 1318485.3750 - accuracy: 0.285210/20 [==============>...............] - ETA: 4s - loss: 1318212.0000 - accuracy: 0.285111/20 [===============>..............] - ETA: 3s - loss: 1317938.8750 - accuracy: 0.286512/20 [=================>............] - ETA: 3s - loss: 1317666.0000 - accuracy: 0.303313/20 [==================>...........] - ETA: 3s - loss: 1317393.2500 - accuracy: 0.318914/20 [====================>.........] - ETA: 2s - loss: 1317120.7500 - accuracy: 0.326215/20 [=====================>........] - ETA: 2s - loss: 1316848.3750 - accuracy: 0.343816/20 [=======================>......] - ETA: 1s - loss: 1316576.2500 - accuracy: 0.344117/20 [========================>.....] - ETA: 1s - loss: 1316304.2500 - accuracy: 0.341518/20 [==========================>...] - ETA: 0s - loss: 1316032.5000 - accuracy: 0.339319/20 [===========================>..] - ETA: 0s - loss: 1315760.8750 - accuracy: 0.358520/20 [==============================] - ETA: 0s - loss: 1315621.6250 - accuracy: 0.366020/20 [==============================] - 27s 732ms/step - loss: 1315621.6250 - accuracy: 0.3660 - val_loss: 1309792.1250 - val_accuracy: 0.5797

Epoch 00001: val_loss improved from inf to 1309792.12500, saving model to weights/bayesian/bayesian-01-0.580-1309792.h5
Current KL Weight is 0.5
Epoch 2/5
 1/20 [>.............................] - ETA: 8s - loss: 1309792.2500 - accuracy: 0.7289 2/20 [==>...........................] - ETA: 7s - loss: 1309523.0000 - accuracy: 0.7121 3/20 [===>..........................] - ETA: 7s - loss: 1309253.8750 - accuracy: 0.7086 4/20 [=====>........................] - ETA: 6s - loss: 1308985.0000 - accuracy: 0.7356 5/20 [======>.......................] - ETA: 6s - loss: 1308716.2500 - accuracy: 0.7373 6/20 [========>.....................] - ETA: 6s - loss: 1308447.6250 - accuracy: 0.6796 7/20 [=========>....................] - ETA: 5s - loss: 1308179.1250 - accuracy: 0.6848 8/20 [===========>..................] - ETA: 5s - loss: 1307910.8750 - accuracy: 0.6383 9/20 [============>.................] - ETA: 4s - loss: 1307642.6250 - accuracy: 0.662810/20 [==============>...............] - ETA: 4s - loss: 1307374.7500 - accuracy: 0.630311/20 [===============>..............] - ETA: 3s - loss: 1307106.8750 - accuracy: 0.625012/20 [=================>............] - ETA: 3s - loss: 1306839.2500 - accuracy: 0.621113/20 [==================>...........] - ETA: 2s - loss: 1306571.7500 - accuracy: 0.640014/20 [====================>.........] - ETA: 2s - loss: 1306304.3750 - accuracy: 0.658515/20 [=====================>........] - ETA: 2s - loss: 1306037.3750 - accuracy: 0.664616/20 [=======================>......] - ETA: 1s - loss: 1305770.3750 - accuracy: 0.679517/20 [========================>.....] - ETA: 1s - loss: 1305503.5000 - accuracy: 0.679518/20 [==========================>...] - ETA: 0s - loss: 1305236.7500 - accuracy: 0.672019/20 [===========================>..] - ETA: 0s - loss: 1304970.2500 - accuracy: 0.685020/20 [==============================] - ETA: 0s - loss: 1304833.5000 - accuracy: 0.691120/20 [==============================] - 11s 566ms/step - loss: 1304833.5000 - accuracy: 0.6911 - val_loss: 1299112.0000 - val_accuracy: 0.8394

Epoch 00002: val_loss improved from 1309792.12500 to 1299112.00000, saving model to weights/bayesian/bayesian-02-0.839-1299112.h5
Current KL Weight is 1.0
Epoch 3/5
 1/20 [>.............................] - ETA: 8s - loss: 1299112.0000 - accuracy: 0.9202 2/20 [==>...........................] - ETA: 7s - loss: 1298847.2500 - accuracy: 0.9192 3/20 [===>..........................] - ETA: 7s - loss: 1298582.6250 - accuracy: 0.9149 4/20 [=====>........................] - ETA: 6s - loss: 1298318.2500 - accuracy: 0.9217 5/20 [======>.......................] - ETA: 6s - loss: 1298054.0000 - accuracy: 0.9278 6/20 [========>.....................] - ETA: 5s - loss: 1297789.8750 - accuracy: 0.9347 7/20 [=========>....................] - ETA: 5s - loss: 1297525.7500 - accuracy: 0.9330 8/20 [===========>..................] - ETA: 5s - loss: 1297261.7500 - accuracy: 0.9378 9/20 [============>.................] - ETA: 4s - loss: 1296997.8750 - accuracy: 0.940710/20 [==============>...............] - ETA: 4s - loss: 1296734.2500 - accuracy: 0.944011/20 [===============>..............] - ETA: 3s - loss: 1296470.6250 - accuracy: 0.945612/20 [=================>............] - ETA: 3s - loss: 1296207.1250 - accuracy: 0.945813/20 [==================>...........] - ETA: 2s - loss: 1295943.8750 - accuracy: 0.948014/20 [====================>.........] - ETA: 2s - loss: 1295680.6250 - accuracy: 0.950215/20 [=====================>........] - ETA: 2s - loss: 1295417.5000 - accuracy: 0.952716/20 [=======================>......] - ETA: 1s - loss: 1295154.5000 - accuracy: 0.954417/20 [========================>.....] - ETA: 1s - loss: 1294891.6250 - accuracy: 0.956118/20 [==========================>...] - ETA: 0s - loss: 1294628.8750 - accuracy: 0.954119/20 [===========================>..] - ETA: 0s - loss: 1294366.2500 - accuracy: 0.956120/20 [==============================] - ETA: 0s - loss: 1294231.6250 - accuracy: 0.956920/20 [==============================] - 11s 566ms/step - loss: 1294231.6250 - accuracy: 0.9569 - val_loss: 1288592.1250 - val_accuracy: 0.9883

Epoch 00003: val_loss improved from 1299112.00000 to 1288592.12500, saving model to weights/bayesian/bayesian-03-0.988-1288592.h5
Current KL Weight is 1.0
Epoch 4/5
 1/20 [>.............................] - ETA: 8s - loss: 1288592.2500 - accuracy: 0.9870 2/20 [==>...........................] - ETA: 7s - loss: 1288331.0000 - accuracy: 0.9899 3/20 [===>..........................] - ETA: 7s - loss: 1288069.8750 - accuracy: 0.9913 4/20 [=====>........................] - ETA: 6s - loss: 1287808.7500 - accuracy: 0.8837 5/20 [======>.......................] - ETA: 6s - loss: 1287547.7500 - accuracy: 0.9046 6/20 [========>.....................] - ETA: 5s - loss: 1287286.7500 - accuracy: 0.9196 7/20 [=========>....................] - ETA: 5s - loss: 1287025.8750 - accuracy: 0.9307 8/20 [===========>..................] - ETA: 5s - loss: 1286765.1250 - accuracy: 0.9388 9/20 [============>.................] - ETA: 4s - loss: 1286504.5000 - accuracy: 0.945210/20 [==============>...............] - ETA: 4s - loss: 1286243.8750 - accuracy: 0.950511/20 [===============>..............] - ETA: 3s - loss: 1285983.5000 - accuracy: 0.954612/20 [=================>............] - ETA: 3s - loss: 1285723.1250 - accuracy: 0.958113/20 [==================>...........] - ETA: 2s - loss: 1285462.7500 - accuracy: 0.961114/20 [====================>.........] - ETA: 2s - loss: 1285202.6250 - accuracy: 0.963815/20 [=====================>........] - ETA: 2s - loss: 1284942.3750 - accuracy: 0.962416/20 [=======================>......] - ETA: 1s - loss: 1284682.2500 - accuracy: 0.964717/20 [========================>.....] - ETA: 1s - loss: 1284422.2500 - accuracy: 0.966718/20 [==========================>...] - ETA: 0s - loss: 1284162.3750 - accuracy: 0.968419/20 [===========================>..] - ETA: 0s - loss: 1283902.5000 - accuracy: 0.970020/20 [==============================] - ETA: 0s - loss: 1283769.3750 - accuracy: 0.970720/20 [==============================] - 11s 567ms/step - loss: 1283769.3750 - accuracy: 0.9707 - val_loss: 1278189.3750 - val_accuracy: 0.9983

Epoch 00004: val_loss improved from 1288592.12500 to 1278189.37500, saving model to weights/bayesian/bayesian-04-0.998-1278189.h5
Current KL Weight is 1.0
Epoch 5/5
 1/20 [>.............................] - ETA: 8s - loss: 1278189.5000 - accuracy: 0.9952 2/20 [==>...........................] - ETA: 7s - loss: 1277930.6250 - accuracy: 0.9973 3/20 [===>..........................] - ETA: 7s - loss: 1277671.8750 - accuracy: 0.9977 4/20 [=====>........................] - ETA: 6s - loss: 1277413.1250 - accuracy: 0.9978 5/20 [======>.......................] - ETA: 6s - loss: 1277154.3750 - accuracy: 0.9981 6/20 [========>.....................] - ETA: 6s - loss: 1276895.8750 - accuracy: 0.9984 7/20 [=========>....................] - ETA: 5s - loss: 1276637.2500 - accuracy: 0.9982 8/20 [===========>..................] - ETA: 5s - loss: 1276378.8750 - accuracy: 0.9984 9/20 [============>.................] - ETA: 4s - loss: 1276120.5000 - accuracy: 0.998510/20 [==============>...............] - ETA: 4s - loss: 1275862.1250 - accuracy: 0.992511/20 [===============>..............] - ETA: 3s - loss: 1275603.8750 - accuracy: 0.993212/20 [=================>............] - ETA: 3s - loss: 1275345.6250 - accuracy: 0.993713/20 [==================>...........] - ETA: 3s - loss: 1275087.5000 - accuracy: 0.994214/20 [====================>.........] - ETA: 2s - loss: 1274829.3750 - accuracy: 0.994515/20 [=====================>........] - ETA: 2s - loss: 1274571.5000 - accuracy: 0.994816/20 [=======================>......] - ETA: 1s - loss: 1274313.5000 - accuracy: 0.995117/20 [========================>.....] - ETA: 1s - loss: 1274055.6250 - accuracy: 0.995418/20 [==========================>...] - ETA: 0s - loss: 1273797.7500 - accuracy: 0.995619/20 [===========================>..] - ETA: 0s - loss: 1273540.0000 - accuracy: 0.995820/20 [==============================] - ETA: 0s - loss: 1273407.7500 - accuracy: 0.995920/20 [==============================] - 11s 567ms/step - loss: 1273407.7500 - accuracy: 0.9959 - val_loss: 1267871.3750 - val_accuracy: 0.9994

Epoch 00005: val_loss improved from 1278189.37500 to 1267871.37500, saving model to weights/bayesian/bayesian-05-0.999-1267871.h5
Current KL Weight is 1.0
